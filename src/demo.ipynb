{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "// Analogous to micrograd Value\n",
    "data class Value(\n",
    "    var data: Double,\n",
    "    var grad: Double = 0.0,\n",
    "    var label: String = (1..3).map { ('H'..'Z').random() }.joinToString(\"\"),\n",
    "    var op: String = \"\",\n",
    "    var backward: () -> Unit = {},\n",
    "    val children: MutableSet<Value> = mutableSetOf()\n",
    ") {\n",
    "    operator fun plus(other: Value): Value {\n",
    "        val out = Value(data + other.data, op = \"$label + ${other.label}\")\n",
    "        out.children.addAll(setOf(this, other))\n",
    "        out.backward = {\n",
    "            this.grad += out.grad\n",
    "            other.grad += out.grad\n",
    "        }\n",
    "        return out\n",
    "    }\n",
    "\n",
    "    operator fun times(other: Value): Value {\n",
    "        val out = Value(data * other.data, op = \"$label * ${other.label}\")\n",
    "        out.children.addAll(setOf(this, other))\n",
    "        out.backward = {\n",
    "            this.grad += other.data * out.grad\n",
    "            other.grad += this.data * out.grad\n",
    "        }\n",
    "        return out\n",
    "    }\n",
    "\n",
    "    fun pow(num: Int): Value {\n",
    "        val out = Value(data.pow(num), op = \"$label**${num}\")\n",
    "        out.children.add(this)\n",
    "        out.backward = {\n",
    "            this.grad += num * this.data.pow(num - 1) * out.grad\n",
    "        }\n",
    "        return out\n",
    "    }\n",
    "\n",
    "    fun relu(): Value {\n",
    "        val out = Value(if (data < 0) 0.0 else data, op = \"$label^ReLu\")\n",
    "        out.children.add(this)\n",
    "        out.backward = {\n",
    "            if (out.data > 0) {\n",
    "                this.grad += out.grad\n",
    "            }\n",
    "        }\n",
    "        return out\n",
    "    }\n",
    "\n",
    "    fun tanh(): Value {\n",
    "        val out = Value(Math.tanh(data), op = \"tanh($label)\")\n",
    "        out.children.add(this)\n",
    "        out.backward = {\n",
    "            grad += (1 - out.data.pow(2)) * out.grad\n",
    "        }\n",
    "\n",
    "        return out\n",
    "    }\n",
    "\n",
    "    fun runBackProp(debug: Boolean = false) {\n",
    "        // Topologically sort Values for backprop\n",
    "        val sorted = mutableListOf<Value>()\n",
    "        val visited = mutableSetOf<Value>()\n",
    "\n",
    "        fun topo(node: Value) {\n",
    "            if (node in visited) return\n",
    "            visited.add(node)\n",
    "            for (child in node.children) {\n",
    "                topo(child)\n",
    "            }\n",
    "            node.grad = 0.0\n",
    "            sorted.add(node)\n",
    "        }\n",
    "        topo(this)\n",
    "\n",
    "        this.grad = 1.0\n",
    "        for (node in sorted.reversed()) {\n",
    "            node.backward()\n",
    "            if (debug) {\n",
    "                println(node)\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    operator fun unaryMinus(): Value = this * -1.0\n",
    "    operator fun plus(otherNumber: Number): Value = this + Value(otherNumber.toDouble())\n",
    "    operator fun minus(other: Value) = this + -other\n",
    "    operator fun minus(otherNumber: Number) = this - Value(otherNumber.toDouble())\n",
    "    operator fun times(otherNumber: Number): Value = this * Value(otherNumber.toDouble())\n",
    "    operator fun div(other: Value): Value = this * other.pow(-1)\n",
    "    operator fun div(otherNumber: Number): Value = this / Value(otherNumber.toDouble())\n",
    "\n",
    "    override fun toString(): String {\n",
    "        return \"Value(data=%.4f,grad=%.4f)\".format(data, grad)\n",
    "        // Used to investigate graph of operations due to lack of diagram library\n",
    "        // return \"Value(data=%.4f,grad=%.4f) $label${if (op.isNotBlank()) \" = $op\" else \"\"}\".format(data, grad)\n",
    "    }\n",
    "}\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "// Extensions for Numerical types\n",
    "operator fun Number.plus(other: Value): Value = other + this\n",
    "operator fun Number.minus(other: Value): Value = this + -other\n",
    "operator fun Number.times(other: Value): Value = other * this\n",
    "operator fun Number.div(other: Value): Value = this * other.pow(-1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "var a = Value(2.0, label = \"a\")\n",
    "var b = Value(-3.0, label = \"b\")\n",
    "var c = Value(10.0, label = \"c\")\n",
    "var e = a * b; e.label = \"e\"\n",
    "var d = e + c; d.label = \"d\"\n",
    "var f = Value(-2.0, label = \"f\")\n",
    "var L = d * f; L.label = \"L\"\n",
    "L.runBackProp()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "var a = Value(-4.0, label = \"a\")\n",
    "var b = Value(2.0, label = \"b\")\n",
    "var c = a + b; c.label = \"c\"\n",
    "var d = a * b + b.pow(3); d.label = \"d\"\n",
    "c += c + 1\n",
    "c += 1 + c + (-a)\n",
    "d += d * 2 + (b + a).relu()\n",
    "d += 3 * d + (b - a).relu()\n",
    "var e = c - d; e.label = \"e\"\n",
    "var f = e.pow(2); f.label = \"f\"\n",
    "var g = f / 2.0; g.label = \"g\"\n",
    "g += 10.0 / f\n",
    "println(\"%.4f\".format(g.data))  // prints 24.7041, the outcome of this forward pass\n",
    "g.runBackProp()\n",
    "println(\"%.4f\".format(a.grad))  // prints 138.8338, i.e. the numerical value of dg/da\n",
    "println(\"%.4f\".format(b.grad))  // prints 645.5773, i.e. the numerical value of dg/db"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class Neuron(inputSize: Int) {\n",
    "    val weights: List<Value> = List(inputSize) { Value(Math.random() * 2 - 1) }\n",
    "    val bias: Value = Value(Math.random() * 2 - 1)\n",
    "    fun parameters(): List<Value> = weights + bias\n",
    "\n",
    "    operator fun invoke(xs: List<Value>): Value {\n",
    "        return xs.zip(weights)\n",
    "            .fold(bias) { acc, (x, w) -> acc + w * x }\n",
    "            .tanh()\n",
    "    }\n",
    "\n",
    "    @JvmName(\"invokeDouble\")\n",
    "    operator fun invoke(xs: List<Double>): Value = invoke(xs.map { Value(it) })\n",
    "}\n",
    "\n",
    "class Layer(inputSize: Int, outputSize: Int) {\n",
    "    val neurons: List<Neuron> = List(outputSize) { Neuron(inputSize) }\n",
    "\n",
    "    operator fun invoke(xs: List<Value>) = neurons.map { it(xs) }\n",
    "\n",
    "    @JvmName(\"invokeDouble\")\n",
    "    operator fun invoke(xs: List<Double>) = this.invoke(xs.map { Value(it) })\n",
    "}\n",
    "\n",
    "class MLP(inputSize: Int, outputSizes: List<Int>) {\n",
    "    val layers: List<Layer> = buildList {\n",
    "        var currentSize = inputSize\n",
    "        for (size in outputSizes) {\n",
    "            add(Layer(currentSize, size))\n",
    "            currentSize = size\n",
    "        }\n",
    "    }\n",
    "\n",
    "    operator fun invoke(xs: List<Value>): List<Value> {\n",
    "        return layers.fold(xs) { acc, layer -> layer(acc) }\n",
    "    }\n",
    "\n",
    "    @JvmName(\"invokeDouble\")\n",
    "    operator fun invoke(xs: List<Double>) = this.invoke(xs.map { Value(it) })\n",
    "\n",
    "    fun parameters(): List<Value> = layers.flatMap { layer -> layer.neurons.flatMap { it.parameters() } }\n",
    "\n",
    "}\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "val x: List<Double> = listOf<Double>(2.0, 3.0, -1.0)\n",
    "val n = MLP(3, listOf(4, 4, 1))\n",
    "\n",
    "n(x)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "val xs = listOf(\n",
    "    listOf(2.0, 3.0, -1.0),\n",
    "    listOf(3.0, -1.0, 0.5),\n",
    "    listOf(0.5, 1.0, 1.0),\n",
    "    listOf(1.0, 1.0, -1.0)\n",
    ")\n",
    "\n",
    "val ys = listOf(1.0, -1.0, -1.0, 1.0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "val h = 0.05\n",
    "for (k in 0..20) {\n",
    "    // Forward pass\n",
    "    val ypreds = xs.map { n(it)[0] }\n",
    "    val loss = ys\n",
    "        .zip(ypreds)\n",
    "        .fold(Value(0.0)) { acc, (ygt, ypred) -> acc + (ypred - ygt).pow(2) }\n",
    "    \n",
    "    // Backward pass\n",
    "    loss.runBackProp()\n",
    "    \n",
    "    // Update\n",
    "    for (p in n.parameters()) {\n",
    "        p.data += h * -p.grad\n",
    "    }\n",
    "    \n",
    "    println(\"$k ${loss.data}\")\n",
    "}"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kotlin",
   "language": "kotlin",
   "name": "kotlin"
  },
  "language_info": {
   "name": "kotlin",
   "version": "1.9.23",
   "mimetype": "text/x-kotlin",
   "file_extension": ".kt",
   "pygments_lexer": "kotlin",
   "codemirror_mode": "text/x-kotlin",
   "nbconvert_exporter": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
